{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugo/Desktop/Projects/MSERT/STT/.envSTT/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading model.bin: 100%|██████████| 3.09G/3.09G [10:14<00:00, 5.03MB/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This CTranslate2 package was not compiled with CUDA support",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/hugo/Desktop/Projects/MSERT/STT/whisperstt.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hugo/Desktop/Projects/MSERT/STT/whisperstt.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model_size \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlarge-v2\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hugo/Desktop/Projects/MSERT/STT/whisperstt.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Run on GPU with FP16\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hugo/Desktop/Projects/MSERT/STT/whisperstt.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m WhisperModel(model_size, device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m, compute_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfloat16\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hugo/Desktop/Projects/MSERT/STT/whisperstt.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# or run on GPU with INT8\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hugo/Desktop/Projects/MSERT/STT/whisperstt.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hugo/Desktop/Projects/MSERT/STT/whisperstt.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# or run on CPU with INT8\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hugo/Desktop/Projects/MSERT/STT/whisperstt.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hugo/Desktop/Projects/MSERT/STT/whisperstt.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m segments, info \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtranscribe(\u001b[39m\"\u001b[39m\u001b[39miemocap.wav\u001b[39m\u001b[39m\"\u001b[39m, beam_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Projects/MSERT/STT/.envSTT/lib/python3.11/site-packages/faster_whisper/transcribe.py:128\u001b[0m, in \u001b[0;36mWhisperModel.__init__\u001b[0;34m(self, model_size_or_path, device, device_index, compute_type, cpu_threads, num_workers, download_root, local_files_only)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     model_path \u001b[39m=\u001b[39m download_model(\n\u001b[1;32m    123\u001b[0m         model_size_or_path,\n\u001b[1;32m    124\u001b[0m         local_files_only\u001b[39m=\u001b[39mlocal_files_only,\n\u001b[1;32m    125\u001b[0m         cache_dir\u001b[39m=\u001b[39mdownload_root,\n\u001b[1;32m    126\u001b[0m     )\n\u001b[0;32m--> 128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m ctranslate2\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mWhisper(\n\u001b[1;32m    129\u001b[0m     model_path,\n\u001b[1;32m    130\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    131\u001b[0m     device_index\u001b[39m=\u001b[39;49mdevice_index,\n\u001b[1;32m    132\u001b[0m     compute_type\u001b[39m=\u001b[39;49mcompute_type,\n\u001b[1;32m    133\u001b[0m     intra_threads\u001b[39m=\u001b[39;49mcpu_threads,\n\u001b[1;32m    134\u001b[0m     inter_threads\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m    135\u001b[0m )\n\u001b[1;32m    137\u001b[0m tokenizer_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_path, \u001b[39m\"\u001b[39m\u001b[39mtokenizer.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(tokenizer_file):\n",
      "\u001b[0;31mValueError\u001b[0m: This CTranslate2 package was not compiled with CUDA support"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "model_size = \"large-v2\"\n",
    "\n",
    "# Run on GPU with FP16\n",
    "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
    "\n",
    "# or run on GPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "# or run on CPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "segments, info = model.transcribe(\"iemocap.wav\", beam_size=5)\n",
    "\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime\n",
    "from onnxruntime_extensions import get_library_path\n",
    "\n",
    "audio_file = \"audio.mp3\"\n",
    "model = \"whisper-tiny-en-all-int8.onnx\"\n",
    "with open(audio_file, \"rb\") as f:\n",
    "    audio = np.asarray(list(f.read()), dtype=np.uint8)\n",
    "\n",
    "inputs = {\n",
    "    \"audio_stream\": np.array([audio]),\n",
    "    \"max_length\": np.array([30], dtype=np.int32),\n",
    "    \"min_length\": np.array([1], dtype=np.int32),\n",
    "    \"num_beams\": np.array([5], dtype=np.int32),\n",
    "    \"num_return_sequences\": np.array([1], dtype=np.int32),\n",
    "    \"length_penalty\": np.array([1.0], dtype=np.float32),\n",
    "    \"repetition_penalty\": np.array([1.0], dtype=np.float32),\n",
    "    \"attention_mask\": np.zeros((1, 80, 3000), dtype=np.int32),\n",
    "}\n",
    "\n",
    "options = onnxruntime.SessionOptions()\n",
    "options.register_custom_ops_library(get_library_path())\n",
    "session = onnxruntime.InferenceSession(model, options, providers=[\"CPUExecutionProvider\"])\n",
    "outputs = session.run(None, inputs)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "import time\n",
    "model_size = \"medium.en\"\n",
    "\n",
    "# Run on GPU with FP16\n",
    "model = WhisperModel(model_size, device=\"cpu\", compute_type=\"float32\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or run on GPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "# or run on CPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "start = time.time()\n",
    "segments, info = model.transcribe(\"iemocap.wav\", beam_size=5)\n",
    "\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "print(\"durée : \", time.time() - start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language 'en' with probability 1.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/hugo/Desktop/Projects/MSERT/STT/whisperstt.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hugo/Desktop/Projects/MSERT/STT/whisperstt.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m segments, info \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtranscribe(\u001b[39m\"\u001b[39m\u001b[39miemocap.wav\u001b[39m\u001b[39m\"\u001b[39m, beam_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hugo/Desktop/Projects/MSERT/STT/whisperstt.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDetected language \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m with probability \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (info\u001b[39m.\u001b[39mlanguage, info\u001b[39m.\u001b[39mlanguage_probability))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hugo/Desktop/Projects/MSERT/STT/whisperstt.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m segment \u001b[39min\u001b[39;00m segments:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hugo/Desktop/Projects/MSERT/STT/whisperstt.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39ms -> \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39ms] \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (segment\u001b[39m.\u001b[39mstart, segment\u001b[39m.\u001b[39mend, segment\u001b[39m.\u001b[39mtext))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hugo/Desktop/Projects/MSERT/STT/whisperstt.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdurée : \u001b[39m\u001b[39m\"\u001b[39m, time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start, \u001b[39m\"\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Projects/MSERT/STT/.envSTT/lib/python3.11/site-packages/faster_whisper/transcribe.py:428\u001b[0m, in \u001b[0;36mWhisperModel.generate_segments\u001b[0;34m(self, features, tokenizer, options, encoder_output)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m encoder_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    421\u001b[0m     encoder_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode(segment)\n\u001b[1;32m    423\u001b[0m (\n\u001b[1;32m    424\u001b[0m     result,\n\u001b[1;32m    425\u001b[0m     avg_logprob,\n\u001b[1;32m    426\u001b[0m     temperature,\n\u001b[1;32m    427\u001b[0m     compression_ratio,\n\u001b[0;32m--> 428\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_with_fallback(encoder_output, prompt, tokenizer, options)\n\u001b[1;32m    430\u001b[0m \u001b[39mif\u001b[39;00m options\u001b[39m.\u001b[39mno_speech_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m     \u001b[39m# no voice activity check\u001b[39;00m\n\u001b[1;32m    432\u001b[0m     should_skip \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mno_speech_prob \u001b[39m>\u001b[39m options\u001b[39m.\u001b[39mno_speech_threshold\n",
      "File \u001b[0;32m~/Desktop/Projects/MSERT/STT/.envSTT/lib/python3.11/site-packages/faster_whisper/transcribe.py:639\u001b[0m, in \u001b[0;36mWhisperModel.generate_with_fallback\u001b[0;34m(self, encoder_output, prompt, tokenizer, options)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    634\u001b[0m     kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    635\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbeam_size\u001b[39m\u001b[39m\"\u001b[39m: options\u001b[39m.\u001b[39mbeam_size,\n\u001b[1;32m    636\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpatience\u001b[39m\u001b[39m\"\u001b[39m: options\u001b[39m.\u001b[39mpatience,\n\u001b[1;32m    637\u001b[0m     }\n\u001b[0;32m--> 639\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m    640\u001b[0m     encoder_output,\n\u001b[1;32m    641\u001b[0m     [prompt],\n\u001b[1;32m    642\u001b[0m     length_penalty\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mlength_penalty,\n\u001b[1;32m    643\u001b[0m     repetition_penalty\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mrepetition_penalty,\n\u001b[1;32m    644\u001b[0m     no_repeat_ngram_size\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mno_repeat_ngram_size,\n\u001b[1;32m    645\u001b[0m     max_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_length,\n\u001b[1;32m    646\u001b[0m     return_scores\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    647\u001b[0m     return_no_speech_prob\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    648\u001b[0m     suppress_blank\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49msuppress_blank,\n\u001b[1;32m    649\u001b[0m     suppress_tokens\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49msuppress_tokens,\n\u001b[1;32m    650\u001b[0m     max_initial_timestamp_index\u001b[39m=\u001b[39;49mmax_initial_timestamp_index,\n\u001b[1;32m    651\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    652\u001b[0m )[\u001b[39m0\u001b[39m]\n\u001b[1;32m    654\u001b[0m tokens \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39msequences_ids[\u001b[39m0\u001b[39m]\n\u001b[1;32m    656\u001b[0m \u001b[39m# Recover the average log prob from the returned score.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "import time\n",
    "model_size = \"medium.en\"\n",
    "\n",
    "model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "start = time.time()\n",
    "segments, info = model.transcribe(\"iemocap.wav\", beam_size=5)\n",
    "\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "print(\"durée : \", time.time() - start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With the custom library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugo/Desktop/Projects/MSERT/STT/.envSTT/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model ...\n",
      "tokenizer path :  /Users/hugo/Desktop/Projects/MSERT/STT/models/medium.en/tokenizer.json\n",
      "Loading the model ...\n",
      "tokenizer path :  /Users/hugo/Desktop/Projects/MSERT/STT/models/medium.en/tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "from custom_faster_whisper import WhisperModel\n",
    "from time import time \n",
    "\n",
    "model_size = \"medium.en\"\n",
    "\n",
    "model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "model_vad = WhisperModel(model_size, vad_activation=True, device=\"cpu\", compute_type=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "segments = model.transcribe(\"iemocap.wav\", beam_size=5)\n",
    "\n",
    "segments_vad = model_vad.transcribe(\"iemocap.wav\", beam_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.4422985017299652 > 0.6\n",
      "not skipping\n",
      "[0.00s -> 5.00s]  Excuse me?\n",
      "[5.00s -> 10.00s]  Do you have your forms?\n",
      "[10.00s -> 11.00s]  Yeah.\n",
      "[11.00s -> 12.00s]  Let me see them.\n",
      "[12.00s -> 18.00s]  Is there a problem?\n",
      "[18.00s -> 19.00s]  Who told you to get in this line?\n",
      "[19.00s -> 20.00s]  You did.\n",
      "[20.00s -> 21.00s]  No.\n",
      "[21.00s -> 23.00s]  You were standing at the beginning.\n",
      "[23.00s -> 24.00s]  You directed me.\n",
      "[24.00s -> 25.00s]  Okay, but I didn't tell you to get in this line\n",
      "[25.00s -> 27.00s]  if you're filling out this particular form.\n",
      "0.6\n",
      "0.5684831142425537 > 0.6\n",
      "not skipping\n",
      "[27.00s -> 29.00s]  Well, what's the problem?\n",
      "[29.00s -> 30.00s]  This form is a ZX4.\n",
      "[30.00s -> 31.00s]  Let me change it.\n",
      "[31.00s -> 33.00s]  You can't...\n",
      "[33.00s -> 35.00s]  This is not the line for the ZX4.\n",
      "[35.00s -> 37.00s]  If you're going to fill out the ZX4,\n",
      "[37.00s -> 39.00s]  you need to have a different form of ID.\n",
      "[39.00s -> 40.00s]  I'm getting an ID.\n",
      "[40.00s -> 41.00s]  This is why I'm here.\n",
      "[41.00s -> 46.00s]  No, I need another set of ID to prove that this is actually you.\n",
      "[46.00s -> 49.00s]  How am I supposed to get an ID without an ID?\n",
      "[49.00s -> 52.00s]  How does a person get an ID in the first place?\n",
      "[52.00s -> 55.00s]  I don't know, but I need an ID to pass this form along.\n",
      "[55.00s -> 56.00s]  I can't just send it along without an ID.\n",
      "0.6\n",
      "0.017165062949061394 > 0.6\n",
      "not skipping\n",
      "[56.00s -> 58.00s]  I'm here to get an ID.\n",
      "[58.00s -> 60.00s]  No, I need another ID.\n",
      "[60.00s -> 62.00s]  A separate one.\n",
      "[62.00s -> 64.00s]  Like what?\n",
      "[64.00s -> 65.00s]  Like a birth certificate?\n",
      "[65.00s -> 66.00s]  A birth certificate.\n",
      "[66.00s -> 67.00s]  A passport.\n",
      "[67.00s -> 69.00s]  Who the hell has a birth certificate?\n",
      "[69.00s -> 70.00s]  A student ID.\n",
      "[70.00s -> 71.00s]  Didn't you go to school?\n",
      "[71.00s -> 72.00s]  Anything?\n",
      "[72.00s -> 74.00s]  Yes, but my wallet was stolen.\n",
      "[74.00s -> 76.00s]  I don't have anything.\n",
      "[76.00s -> 77.00s]  I don't have any credit cards.\n",
      "[77.00s -> 79.00s]  I don't have my ID.\n",
      "[79.00s -> 81.00s]  Don't you have things on file here?\n",
      "[81.00s -> 82.00s]  Yeah, we keep it on file,\n",
      "[82.00s -> 85.00s]  but we need an ID to access that file.\n",
      "0.6\n",
      "0.01764846034348011 > 0.6\n",
      "not skipping\n",
      "[85.00s -> 87.00s]  That's out of control.\n",
      "[87.00s -> 90.00s]  I don't understand why this is so complicated for people\n",
      "[90.00s -> 91.00s]  when they get here.\n",
      "[91.00s -> 92.00s]  It's just a simple form.\n",
      "[92.00s -> 93.00s]  I just need an ID.\n",
      "[93.00s -> 95.00s]  How long have you been working here?\n",
      "[95.00s -> 98.00s]  I'd say too long.\n",
      "[98.00s -> 99.00s]  Clearly.\n",
      "[99.00s -> 102.00s]  You know, do you have like a supervisor or something?\n",
      "[102.00s -> 103.00s]  Yeah.\n",
      "[103.00s -> 104.00s]  You want to see my supervisor?\n",
      "[104.00s -> 105.00s]  Huh?\n",
      "[105.00s -> 106.00s]  Yeah, you want to see my supervisor?\n",
      "[106.00s -> 113.00s]  Fine, I'll be right back.\n",
      "[113.00s -> 114.00s]  Is that the end?\n",
      "0.6\n",
      "0.10718022286891937 > 0.6\n",
      "not skipping\n",
      "[115.00s -> 117.00s]  He walks away.\n",
      "[120.00s -> 122.00s]  Okay, hold the camera, please.\n",
      "[122.00s -> 127.00s]  Microphones.\n",
      "[127.00s -> 133.00s]  So this is spontaneous 2.\n",
      "durée :  191.74892592430115 s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "print(\"durée : \", time() - start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2508130669593811 > 0.6\n",
      "[6.58s -> 8.58s]  Excuse me.\n",
      "[8.74s -> 20.07s]  Do you have your forms? Yeah. Let me see them. Is there a problem? Who told you to get in this line? You did.\n",
      "[22.11s -> 27.21s]  You were standing at the beginning, you directed me. Okay, but I didn't tell you to get in this line if you're filling out this particular form.\n",
      "[27.69s -> 35.33s]  Well, what's the problem? What's the problem? Let me change it. This is not the line for the ZX4.\n",
      "[35.33s -> 38.73s]  If you're gonna fill out the ZX4, you need to have a different form of ID.\n",
      "0.009213976562023163 > 0.6\n",
      "[39.05s -> 46.61s]  I'm getting an ID. This is why I'm here. No, I need another set of ID to prove that this is actually you.\n",
      "[46.61s -> 48.71s]  How am I supposed to get an ID without an ID?\n",
      "[49.33s -> 51.37s]  How does the person get an ID in the first place?\n",
      "[51.37s -> 55.23s]  I don't know, but I need an ID to pass this form along.\n",
      "[55.23s -> 57.85s]  I can't just send it along without an ID. I'm here to get an ID.\n",
      "[58.41s -> 63.07s]  No, I need another ID. A separate one. Like what?\n",
      "0.0071402015164494514 > 0.6\n",
      "[64.07s -> 69.07s]  Like a birth certificate? A birth certificate. A password. Who the hell has a birth certificate?\n",
      "[69.77s -> 71.77s]  A student ID. Didn't you go to school?\n",
      "[71.95s -> 77.77s]  Anything? Yes, but my wallet was stolen. I don't have anything. I don't have any credit cards.\n",
      "[77.77s -> 81.49s]  I don't have my ID. Don't you have things on file here?\n",
      "[81.91s -> 86.91s]  Yeah, we keep it on file, but we need an ID to access that file. That's out of control.\n",
      "[87.99s -> 92.65s]  I don't understand why this is so complicated for people when they get here. It's just a simple form.\n",
      "0.004317301791161299 > 0.6\n",
      "[92.73s -> 95.21s]  I just need an ID. How long have you been working here?\n",
      "[95.21s -> 98.58s]  I'd say too long.\n",
      "[98.58s -> 99.78s]  Clearly.\n",
      "[99.78s -> 104.14s]  You know, do you have like a supervisor or something? Yeah, you want to see my supervisor?\n",
      "[104.14s -> 106.86s]  Huh? Yeah, you want to see my supervisor? Fine, I'll be right back.\n",
      "[116.23s -> 127.86s]  He walks away.\n",
      "durée :  147.13541460037231 s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "for segment in segments_vad:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "print(\"durée : \", time() - start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
