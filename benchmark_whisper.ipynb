{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With the custom library - Faster-whisper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model ...\n",
      "tokenizer path :  /Users/hugo/Desktop/Projects/inference_whisper_benchmark/fast_whisper/models/medium.en/tokenizer.json\n",
      "Loading the model ...\n",
      "tokenizer path :  /Users/hugo/Desktop/Projects/inference_whisper_benchmark/fast_whisper/models/medium.en/tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "from fast_whisper.fast_whisper import WhisperModel\n",
    "from time import time \n",
    "\n",
    "model_size = \"medium.en\"\n",
    "\n",
    "model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "model_vad = WhisperModel(model_size, vad_activation=True, device=\"cpu\", compute_type=\"int8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without VAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_3 = model.transcribe(\"audio/3sec.wav\", beam_size=5)\n",
    "segments_6 = model.transcribe(\"audio/6sec.wav\", beam_size=5)\n",
    "segments_10 = model.transcribe(\"audio/10sec.wav\", beam_size=5)\n",
    "segments_2min11 = model.transcribe(\"audio/2min11.wav\", beam_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with VAD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchFile",
     "evalue": "[ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /Users/hugo/Desktop/Projects/inference_whisper_benchmark/fast_whisper/assets/silero_vad.onnx failed:Load model /Users/hugo/Desktop/Projects/inference_whisper_benchmark/fast_whisper/assets/silero_vad.onnx failed. File doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchFile\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/hugo/Desktop/Projects/inference_whisper_benchmark/benchmark_whisper.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hugo/Desktop/Projects/inference_whisper_benchmark/benchmark_whisper.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m segments_3_vad \u001b[39m=\u001b[39m model_vad\u001b[39m.\u001b[39;49mtranscribe(\u001b[39m\"\u001b[39;49m\u001b[39maudio/3sec.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m, beam_size\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hugo/Desktop/Projects/inference_whisper_benchmark/benchmark_whisper.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m segments_6_vad \u001b[39m=\u001b[39m model_vad\u001b[39m.\u001b[39mtranscribe(\u001b[39m\"\u001b[39m\u001b[39maudio/6sec.wav\u001b[39m\u001b[39m\"\u001b[39m, beam_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hugo/Desktop/Projects/inference_whisper_benchmark/benchmark_whisper.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m segments_10_vad \u001b[39m=\u001b[39m model_vad\u001b[39m.\u001b[39mtranscribe(\u001b[39m\"\u001b[39m\u001b[39maudio/10sec.wav\u001b[39m\u001b[39m\"\u001b[39m, beam_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Projects/inference_whisper_benchmark/fast_whisper/fast_whisper.py:296\u001b[0m, in \u001b[0;36mWhisperModel.transcribe\u001b[0;34m(self, audio, language, task, beam_size, best_of, patience, length_penalty, repetition_penalty, no_repeat_ngram_size, temperature, compression_ratio_threshold, log_prob_threshold, no_speech_threshold, condition_on_previous_text, prompt_reset_on_temperature, prefix, suppress_blank, suppress_tokens, without_timestamps, max_initial_timestamp, word_timestamps, prepend_punctuations, append_punctuations, vad_parameters)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(vad_parameters, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    295\u001b[0m     vad_parameters \u001b[39m=\u001b[39m VadOptions(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mvad_parameters)\n\u001b[0;32m--> 296\u001b[0m speech_chunks \u001b[39m=\u001b[39m get_speech_timestamps(audio, vad_parameters)\n\u001b[1;32m    297\u001b[0m audio \u001b[39m=\u001b[39m collect_chunks(audio, speech_chunks)\n\u001b[1;32m    298\u001b[0m duration_after_vad \u001b[39m=\u001b[39m audio\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m sampling_rate\n",
      "File \u001b[0;32m~/Desktop/Projects/inference_whisper_benchmark/fast_whisper/vad.py:90\u001b[0m, in \u001b[0;36mget_speech_timestamps\u001b[0;34m(audio, vad_options, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m min_silence_samples_at_max_speech \u001b[39m=\u001b[39m sampling_rate \u001b[39m*\u001b[39m \u001b[39m98\u001b[39m \u001b[39m/\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m     88\u001b[0m audio_length_samples \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(audio)\n\u001b[0;32m---> 90\u001b[0m model \u001b[39m=\u001b[39m get_vad_model()\n\u001b[1;32m     91\u001b[0m state \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_initial_state(batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     93\u001b[0m speech_probs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/Desktop/Projects/inference_whisper_benchmark/fast_whisper/vad.py:245\u001b[0m, in \u001b[0;36mget_vad_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the VAD model instance.\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(get_assets_path(), \u001b[39m\"\u001b[39m\u001b[39msilero_vad.onnx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 245\u001b[0m \u001b[39mreturn\u001b[39;00m SileroVADModel(path)\n",
      "File \u001b[0;32m~/Desktop/Projects/inference_whisper_benchmark/fast_whisper/vad.py:262\u001b[0m, in \u001b[0;36mSileroVADModel.__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    259\u001b[0m opts\u001b[39m.\u001b[39mintra_op_num_threads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    260\u001b[0m opts\u001b[39m.\u001b[39mlog_severity_level \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[0;32m--> 262\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m onnxruntime\u001b[39m.\u001b[39;49mInferenceSession(\n\u001b[1;32m    263\u001b[0m     path,\n\u001b[1;32m    264\u001b[0m     providers\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mCPUExecutionProvider\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    265\u001b[0m     sess_options\u001b[39m=\u001b[39;49mopts,\n\u001b[1;32m    266\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_bench/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:419\u001b[0m, in \u001b[0;36mInferenceSession.__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m disabled_optimizers \u001b[39m=\u001b[39m kwargs[\u001b[39m\"\u001b[39m\u001b[39mdisabled_optimizers\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdisabled_optimizers\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_inference_session(providers, provider_options, disabled_optimizers)\n\u001b[1;32m    420\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    421\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_fallback:\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_bench/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:460\u001b[0m, in \u001b[0;36mInferenceSession._create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    458\u001b[0m session_options \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess_options \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess_options \u001b[39melse\u001b[39;00m C\u001b[39m.\u001b[39mget_default_session_options()\n\u001b[1;32m    459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_path:\n\u001b[0;32m--> 460\u001b[0m     sess \u001b[39m=\u001b[39m C\u001b[39m.\u001b[39;49mInferenceSession(session_options, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model_path, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_config_from_model)\n\u001b[1;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     sess \u001b[39m=\u001b[39m C\u001b[39m.\u001b[39mInferenceSession(session_options, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_bytes, \u001b[39mFalse\u001b[39;00m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_config_from_model)\n",
      "\u001b[0;31mNoSuchFile\u001b[0m: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /Users/hugo/Desktop/Projects/inference_whisper_benchmark/fast_whisper/assets/silero_vad.onnx failed:Load model /Users/hugo/Desktop/Projects/inference_whisper_benchmark/fast_whisper/assets/silero_vad.onnx failed. File doesn't exist"
     ]
    }
   ],
   "source": [
    "segments_3_vad = model_vad.transcribe(\"audio/3sec.wav\", beam_size=5)\n",
    "segments_6_vad = model_vad.transcribe(\"audio/6sec.wav\", beam_size=5)\n",
    "segments_10_vad = model_vad.transcribe(\"audio/10sec.wav\", beam_size=5)\n",
    "segments_2min11_vad = model_vad.transcribe(\"audio/2min11.wav\", beam_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "(80, 3000)\n",
      "2.56\n",
      "0.6\n",
      "0.04850371927022934 > 0.6\n",
      "not skipping\n",
      "[0.00s -> 2.00s]  I just don't. It's stupid.\n",
      "durée :  8.325692176818848 s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "for segment in segments_2:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "print(\"durée : \", time() - start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "(80, 3000)\n",
      "2.2\n",
      "0.6\n",
      "0.016265036538243294 > 0.6\n",
      "not skipping\n",
      "[0.37s -> 2.37s]  I just don't. It's stupid.\n",
      "durée :  8.500772714614868 s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "for segment in segments_vad_2:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "print(\"durée : \", time() - start, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "(80, 3000)\n",
      "30.0\n",
      "0.6\n",
      "0.4422985017299652 > 0.6\n",
      "not skipping\n",
      "[0.00s -> 5.00s]  Excuse me?\n",
      "[5.00s -> 10.00s]  Do you have your forms?\n",
      "[10.00s -> 11.00s]  Yeah.\n",
      "[11.00s -> 12.00s]  Let me see them.\n",
      "[12.00s -> 18.00s]  Is there a problem?\n",
      "[18.00s -> 19.00s]  Who told you to get in this line?\n",
      "[19.00s -> 20.00s]  You did.\n",
      "[20.00s -> 21.00s]  No.\n",
      "[21.00s -> 23.00s]  You were standing at the beginning.\n",
      "[23.00s -> 24.00s]  You directed me.\n",
      "[24.00s -> 25.00s]  Okay, but I didn't tell you to get in this line\n",
      "[25.00s -> 27.00s]  if you're filling out this particular form.\n",
      "3000\n",
      "(80, 3000)\n",
      "30.0\n",
      "0.6\n",
      "0.5684831142425537 > 0.6\n",
      "not skipping\n",
      "[27.00s -> 29.00s]  Well, what's the problem?\n",
      "[29.00s -> 30.00s]  This form is a ZX4.\n",
      "[30.00s -> 31.00s]  Let me change it.\n",
      "[31.00s -> 33.00s]  You can't...\n",
      "[33.00s -> 35.00s]  This is not the line for the ZX4.\n",
      "[35.00s -> 37.00s]  If you're going to fill out the ZX4,\n",
      "[37.00s -> 39.00s]  you need to have a different form of ID.\n",
      "[39.00s -> 40.00s]  I'm getting an ID.\n",
      "[40.00s -> 41.00s]  This is why I'm here.\n",
      "[41.00s -> 46.00s]  No, I need another set of ID to prove that this is actually you.\n",
      "[46.00s -> 49.00s]  How am I supposed to get an ID without an ID?\n",
      "[49.00s -> 52.00s]  How does a person get an ID in the first place?\n",
      "[52.00s -> 55.00s]  I don't know, but I need an ID to pass this form along.\n",
      "[55.00s -> 56.00s]  I can't just send it along without an ID.\n",
      "3000\n",
      "(80, 3000)\n",
      "30.0\n",
      "0.6\n",
      "0.017165062949061394 > 0.6\n",
      "not skipping\n",
      "[56.00s -> 58.00s]  I'm here to get an ID.\n",
      "[58.00s -> 60.00s]  No, I need another ID.\n",
      "[60.00s -> 62.00s]  A separate one.\n",
      "[62.00s -> 64.00s]  Like what?\n",
      "[64.00s -> 65.00s]  Like a birth certificate?\n",
      "[65.00s -> 66.00s]  A birth certificate.\n",
      "[66.00s -> 67.00s]  A passport.\n",
      "[67.00s -> 69.00s]  Who the hell has a birth certificate?\n",
      "[69.00s -> 70.00s]  A student ID.\n",
      "[70.00s -> 71.00s]  Didn't you go to school?\n",
      "[71.00s -> 72.00s]  Anything?\n",
      "[72.00s -> 74.00s]  Yes, but my wallet was stolen.\n",
      "[74.00s -> 76.00s]  I don't have anything.\n",
      "[76.00s -> 77.00s]  I don't have any credit cards.\n",
      "[77.00s -> 79.00s]  I don't have my ID.\n",
      "[79.00s -> 81.00s]  Don't you have things on file here?\n",
      "[81.00s -> 82.00s]  Yeah, we keep it on file,\n",
      "[82.00s -> 85.00s]  but we need an ID to access that file.\n",
      "3000\n",
      "(80, 3000)\n",
      "30.0\n",
      "0.6\n",
      "0.01764846034348011 > 0.6\n",
      "not skipping\n",
      "[85.00s -> 87.00s]  That's out of control.\n",
      "[87.00s -> 90.00s]  I don't understand why this is so complicated for people\n",
      "[90.00s -> 91.00s]  when they get here.\n",
      "[91.00s -> 92.00s]  It's just a simple form.\n",
      "[92.00s -> 93.00s]  I just need an ID.\n",
      "[93.00s -> 95.00s]  How long have you been working here?\n",
      "[95.00s -> 98.00s]  I'd say too long.\n",
      "[98.00s -> 99.00s]  Clearly.\n",
      "[99.00s -> 102.00s]  You know, do you have like a supervisor or something?\n",
      "[102.00s -> 103.00s]  Yeah.\n",
      "[103.00s -> 104.00s]  You want to see my supervisor?\n",
      "[104.00s -> 105.00s]  Huh?\n",
      "[105.00s -> 106.00s]  Yeah, you want to see my supervisor?\n",
      "[106.00s -> 113.00s]  Fine, I'll be right back.\n",
      "[113.00s -> 114.00s]  Is that the end?\n",
      "3000\n",
      "(80, 3000)\n",
      "19.62\n",
      "0.6\n",
      "0.10718022286891937 > 0.6\n",
      "not skipping\n",
      "[115.00s -> 117.00s]  He walks away.\n",
      "[120.00s -> 122.00s]  Okay, hold the camera, please.\n",
      "[122.00s -> 127.00s]  Microphones.\n",
      "[127.00s -> 133.00s]  So this is spontaneous 2.\n",
      "durée :  199.70673608779907 s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "print(\"durée : \", time() - start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2508130669593811 > 0.6\n",
      "[6.58s -> 8.58s]  Excuse me.\n",
      "[8.74s -> 20.07s]  Do you have your forms? Yeah. Let me see them. Is there a problem? Who told you to get in this line? You did.\n",
      "[22.11s -> 27.21s]  You were standing at the beginning, you directed me. Okay, but I didn't tell you to get in this line if you're filling out this particular form.\n",
      "[27.69s -> 35.33s]  Well, what's the problem? What's the problem? Let me change it. This is not the line for the ZX4.\n",
      "[35.33s -> 38.73s]  If you're gonna fill out the ZX4, you need to have a different form of ID.\n",
      "0.009213976562023163 > 0.6\n",
      "[39.05s -> 46.61s]  I'm getting an ID. This is why I'm here. No, I need another set of ID to prove that this is actually you.\n",
      "[46.61s -> 48.71s]  How am I supposed to get an ID without an ID?\n",
      "[49.33s -> 51.37s]  How does the person get an ID in the first place?\n",
      "[51.37s -> 55.23s]  I don't know, but I need an ID to pass this form along.\n",
      "[55.23s -> 57.85s]  I can't just send it along without an ID. I'm here to get an ID.\n",
      "[58.41s -> 63.07s]  No, I need another ID. A separate one. Like what?\n",
      "0.0071402015164494514 > 0.6\n",
      "[64.07s -> 69.07s]  Like a birth certificate? A birth certificate. A password. Who the hell has a birth certificate?\n",
      "[69.77s -> 71.77s]  A student ID. Didn't you go to school?\n",
      "[71.95s -> 77.77s]  Anything? Yes, but my wallet was stolen. I don't have anything. I don't have any credit cards.\n",
      "[77.77s -> 81.49s]  I don't have my ID. Don't you have things on file here?\n",
      "[81.91s -> 86.91s]  Yeah, we keep it on file, but we need an ID to access that file. That's out of control.\n",
      "[87.99s -> 92.65s]  I don't understand why this is so complicated for people when they get here. It's just a simple form.\n",
      "0.004317301791161299 > 0.6\n",
      "[92.73s -> 95.21s]  I just need an ID. How long have you been working here?\n",
      "[95.21s -> 98.58s]  I'd say too long.\n",
      "[98.58s -> 99.78s]  Clearly.\n",
      "[99.78s -> 104.14s]  You know, do you have like a supervisor or something? Yeah, you want to see my supervisor?\n",
      "[104.14s -> 106.86s]  Huh? Yeah, you want to see my supervisor? Fine, I'll be right back.\n",
      "[116.23s -> 127.86s]  He walks away.\n",
      "durée :  147.13541460037231 s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "for segment in segments_vad:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "print(\"durée : \", time() - start, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time : \n",
    "Long file -> \n",
    "Small file -> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Whisper.cpp Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/stlukey/whispercpp.py\n",
      "  Cloning https://github.com/stlukey/whispercpp.py to /private/var/folders/3t/6vk3vg696px0cpvl0hqnmnc40000gn/T/pip-req-build-d47lcx06\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/stlukey/whispercpp.py /private/var/folders/3t/6vk3vg696px0cpvl0hqnmnc40000gn/T/pip-req-build-d47lcx06\n",
      "  Resolved https://github.com/stlukey/whispercpp.py to commit 7af678159c29edb3bc2a51a72665073d58f2352f\n",
      "  Running command git submodule update --init --recursive -q\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/hugo/anaconda3/envs/whisper/lib/python3.9/site-packages (from whispercpp==1.0) (1.25.2)\n",
      "Collecting ffmpeg-python (from whispercpp==1.0)\n",
      "  Using cached ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: requests in /Users/hugo/anaconda3/envs/whisper/lib/python3.9/site-packages (from whispercpp==1.0) (2.31.0)\n",
      "Collecting future (from ffmpeg-python->whispercpp==1.0)\n",
      "  Using cached future-0.18.3-py3-none-any.whl\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hugo/anaconda3/envs/whisper/lib/python3.9/site-packages (from requests->whispercpp==1.0) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hugo/anaconda3/envs/whisper/lib/python3.9/site-packages (from requests->whispercpp==1.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hugo/anaconda3/envs/whisper/lib/python3.9/site-packages (from requests->whispercpp==1.0) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hugo/anaconda3/envs/whisper/lib/python3.9/site-packages (from requests->whispercpp==1.0) (2023.7.22)\n",
      "Building wheels for collected packages: whispercpp\n",
      "  Building wheel for whispercpp (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for whispercpp \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[32 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m whisper.cpp/ggml.c:5811:15: warning: unused variable 'ne12' [-Wunused-variable]\n",
      "  \u001b[31m   \u001b[0m     const int ne12 = src1->ne[2];\n",
      "  \u001b[31m   \u001b[0m               ^\n",
      "  \u001b[31m   \u001b[0m whisper.cpp/ggml.c:5812:15: warning: unused variable 'ne13' [-Wunused-variable]\n",
      "  \u001b[31m   \u001b[0m     const int ne13 = src1->ne[3];\n",
      "  \u001b[31m   \u001b[0m               ^\n",
      "  \u001b[31m   \u001b[0m whisper.cpp/ggml.c:5814:15: warning: unused variable 'ne0' [-Wunused-variable]\n",
      "  \u001b[31m   \u001b[0m     const int ne0  = dst->ne[0];\n",
      "  \u001b[31m   \u001b[0m               ^\n",
      "  \u001b[31m   \u001b[0m whisper.cpp/ggml.c:5815:15: warning: unused variable 'ne1' [-Wunused-variable]\n",
      "  \u001b[31m   \u001b[0m     const int ne1  = dst->ne[1];\n",
      "  \u001b[31m   \u001b[0m               ^\n",
      "  \u001b[31m   \u001b[0m whisper.cpp/ggml.c:5816:15: warning: unused variable 'ne2' [-Wunused-variable]\n",
      "  \u001b[31m   \u001b[0m     const int ne2  = dst->ne[2];\n",
      "  \u001b[31m   \u001b[0m               ^\n",
      "  \u001b[31m   \u001b[0m whisper.cpp/ggml.c:5817:15: warning: unused variable 'ne3' [-Wunused-variable]\n",
      "  \u001b[31m   \u001b[0m     const int ne3  = dst->ne[3];\n",
      "  \u001b[31m   \u001b[0m               ^\n",
      "  \u001b[31m   \u001b[0m whisper.cpp/ggml.c:5820:15: warning: unused variable 'nb00' [-Wunused-variable]\n",
      "  \u001b[31m   \u001b[0m     const int nb00 = src0->nb[0];\n",
      "  \u001b[31m   \u001b[0m               ^\n",
      "  \u001b[31m   \u001b[0m whisper.cpp/ggml.c:1433:20: warning: unused function 'ggml_vec_acc_f32' [-Wunused-function]\n",
      "  \u001b[31m   \u001b[0m inline static void ggml_vec_acc_f32 (const int n, float * y, const float * x)                  { for (int i = 0; i < n; ++i) y[i] += x[i];        }\n",
      "  \u001b[31m   \u001b[0m                    ^\n",
      "  \u001b[31m   \u001b[0m whisper.cpp/ggml.c:2142:20: warning: unused function 'ggml_vec_silu_f16' [-Wunused-function]\n",
      "  \u001b[31m   \u001b[0m inline static void ggml_vec_silu_f16(const int n, ggml_fp16_t * y, const ggml_fp16_t * x) {\n",
      "  \u001b[31m   \u001b[0m                    ^\n",
      "  \u001b[31m   \u001b[0m whisper.cpp/ggml.c:2555:19: warning: unused function 'ggml_up64' [-Wunused-function]\n",
      "  \u001b[31m   \u001b[0m static inline int ggml_up64(int n) {\n",
      "  \u001b[31m   \u001b[0m                   ^\n",
      "  \u001b[31m   \u001b[0m 10 warnings generated.\n",
      "  \u001b[31m   \u001b[0m error: command '/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_58wdpicaui/croot/python-split_1694437936442/_build_env/bin/llvm-ar' failed: No such file or directory\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for whispercpp\u001b[0m\u001b[31m\n",
      "\u001b[0mFailed to build whispercpp\n",
      "\u001b[31mERROR: Could not build wheels for whispercpp, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/stlukey/whispercpp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Whisper Jax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from [git](https://github.com/sanchit-gandhi/whisper-jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whisper_jax import FlaxWhisperPipline\n",
    "\n",
    "# instantiate pipeline\n",
    "pipeline = FlaxWhisperPipline(\"openai/whisper-large-v2\")\n",
    "\n",
    "# JIT compile the forward call - slow, but we only do once\n",
    "text = pipeline(\"audio.mp3\")\n",
    "\n",
    "# used cached function thereafter - super fast!!\n",
    "text = pipeline(\"audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whisper_jax import FlaxWhisperPipline\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# instantiate pipeline in bfloat16\n",
    "pipeline = FlaxWhisperPipline(\"openai/whisper-large-v2\", dtype=jnp.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time : \n",
    "Long file -> \n",
    "Small file -> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
